{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics.nn.tasks import DetectionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle .best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition des classes et du choix de la classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_choisie = \"2x4_Jaune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"1x2_Blanc\",\n",
    "    \"1x2_Bleu\",\n",
    "    \"1x2_Jaune\",\n",
    "    \"1x2_Marron\",\n",
    "    \"1x2_Noir\",\n",
    "    \"1x2_Rouge\",\n",
    "    \"1x2_Vert clear\",\n",
    "    \"1x2_Vert dark\",\n",
    "    \"1x4_Blanc\",\n",
    "    \"1x4_Jaune\",\n",
    "    \"1x4_Noir\",\n",
    "    \"1x4_Rouge\",\n",
    "    \"1x4_Vert clear\",\n",
    "    \"1x4_Vert dark\",\n",
    "    \"2x2_Blanc\",\n",
    "    \"2x2_Bleu\",\n",
    "    \"2x2_Jaune\",\n",
    "    \"2x2_Marron\",\n",
    "    \"2x2_Rouge\",\n",
    "    \"2x2_Vert clear\",\n",
    "    \"2x2_Vert dark\",\n",
    "    \"2x4_Blanc\",\n",
    "    \"2x4_Bleu\",\n",
    "    \"2x4_Jaune\",\n",
    "    \"2x4_Rouge\",\n",
    "    \"2x4_Vert dark\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de traitement pour la video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration initiale\n",
    "VIDEO_SOURCE = \"/home/dim/clone_repo/BrickSearch/data/raw/videos/lego_video_test.mp4\"\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "MODEL_NAME = \"y12x_100_640_3000_16_0_065\"\n",
    "MODEL_PATH = f\"/home/dim/clone_repo/BrickSearch/outputs/output_models/{MODEL_NAME}/weights/best.pt\"\n",
    "OUTPUT_FILE = \"/home/dim/clone_repo/BrickSearch/outputs/video_annotees/result_\" + VIDEO_SOURCE.replace(\"/home/dim/clone_repo/BrickSearch/data/raw/videos/\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    \"\"\"\n",
    "    Initialise les modèles .\n",
    "\n",
    "    Returns:\n",
    "        yolo_model entrainé lego: \n",
    "    \"\"\"\n",
    "# Chargement du modèle sur le GPU \n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cuda'))\n",
    "\n",
    "    model = checkpoint['model']\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_video_capture_and_writer():\n",
    "    \"\"\"\n",
    "    Initialise la capture vidéo et l'écriture vidéo.\n",
    "\n",
    "    Returns:\n",
    "        cap: Objet de capture vidéo.\n",
    "        video_writer: Objet d'écriture vidéo.\n",
    "    \"\"\"    \n",
    "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') # type: ignore\n",
    "    video_writer = cv2.VideoWriter(OUTPUT_FILE, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "    return cap, video_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frame(frame):\n",
    "        # réccupération de la taille de l'image initiale\n",
    "        height_img_init, width_img_init = frame.shape[:2]\n",
    "\n",
    "        # Conversion de BGR vers RGB et redimensionnement (ici à 640x640, idem à modele entrainné)\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image_resized = cv2.resize(image_rgb, (640, 640))\n",
    "\n",
    "        # Conversion en tensor, normalisation, ajout de la dimension batch,\n",
    "        # transfert sur GPU et conversion en half precision\n",
    "        input_tensor = torch.from_numpy(image_resized).permute(2, 0, 1).float() / 255.0\n",
    "        input_tensor = input_tensor.unsqueeze(0)  # Ajout de la dimension batch\n",
    "        input_tensor = input_tensor.to(torch.device('cuda')).half()  # Passage en fp16\n",
    "\n",
    "        return input_tensor, height_img_init, width_img_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, input_tensor): #\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_tensor) #, stream=True, iou=0.45, max_det=1000, vid_stride=5, batch_size=5, agnostic_nms=True)\n",
    "    \n",
    "    # Réorganisation de la sortie :\n",
    "    # La prédiction initiale a la forme [1, 30, 8400]. On souhaite obtenir un tenseur de forme [8400, 30].\n",
    "    tensor_predictions = predictions[0]\n",
    "    preds = tensor_predictions.squeeze(0).transpose(0, 1) # shape : [8400, 30]\n",
    "    # predictions est un tenseur PyTorch, on le convertit en numpy pour faciliter le traitement avec OpenCV\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_rectangle_and_text(x1, y1, x2, y2, class_idx, max_class_score, frame, height_img_init, width_img_init):\n",
    "    # on réajuste à la taille de limage initiale\n",
    "    # x1, y1 : coordonnées du centre de la boîte\n",
    "    # x2, y2 : dimensions de la boîte\n",
    "    x1 = (float(x1) * float(width_img_init) / 640.0)\n",
    "    y1 = (float(y1) * float(height_img_init) / 640.0)\n",
    "    x2 = (float(x2) * float(width_img_init) / 640.0)\n",
    "    y2 = (float(y2) * float(height_img_init) / 640.0)\n",
    "\n",
    "    # On defini les point d'encadrement de la boîte englobante\n",
    "        # x1, y1 : coordonnées du centre de la boîte\n",
    "        # x2, y2 : dimensions de la boîte\n",
    "    start_point = (int(x1-(x2/2)), int(y1-(y2/2)))\n",
    "    end_point   = (int(x1+(x2/2)), int(y1+(y2/2)))\n",
    "\n",
    "    # Dessine le rectangle \n",
    "    cv2.rectangle(frame, start_point, end_point, color=(102, 178, 255), thickness=2)\n",
    "    \n",
    "    # Prépare le texte à annoter (nom de la classe et score)\n",
    "    label = f\"{classes[class_idx]}: {max_class_score:.2f}\"\n",
    "    \n",
    "    # Place le texte au-dessus de la boîte\n",
    "    cv2.putText(frame, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.5, (102, 178, 255), thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotationner_frame(model, frame, classe_choisie):\n",
    "\n",
    "    # préparation de l'image à traiter\n",
    "    input_tensor, height_img_init, width_img_init = prepare_frame(frame)\n",
    "\n",
    "    # Inference\n",
    "    preds = prediction(model, input_tensor)\n",
    "\n",
    "    # Iterration sur les prédictions\n",
    "    for pred in preds: \n",
    "        # Extraction des coordonnées pour la boîte englobante\n",
    "        x1, y1, x2, y2 = pred[:4]\n",
    "\n",
    "        # récupèration du score maximum parmi les classes et son indice\n",
    "        class_scores = pred[4:]\n",
    "        max_class_score = np.max(class_scores)\n",
    "        class_idx = np.argmax(class_scores)\n",
    "        \n",
    "        # On vérifie que le score de la classe prédite est supérieur au seuil et uniquement pour la classe cherchée\n",
    "        if max_class_score > CONFIDENCE_THRESHOLD and classe_choisie == classes[class_idx] :\n",
    "            \n",
    "            # On dessine la boîte englobante et le texte\n",
    "            write_rectangle_and_text(x1, y1, x2, y2, class_idx, max_class_score, frame, height_img_init, width_img_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(classe_choisie):\n",
    "    \"\"\"\n",
    "    Traite la vidéo en détectant, suivant et annotant les objets et les poses.\n",
    "    \"\"\"\n",
    "\n",
    "    # Définition des paramètres de la fenêtre d'affichage\n",
    "    WINDOW_NAME = 'YOLOv8 Detection'\n",
    "    WINDOW_WIDTH = 800   # Nouvelle largeur souhaitée\n",
    "    WINDOW_HEIGHT = 600  # Nouvelle hauteur souhaitée\n",
    "    WINDOW_POS_X = 100   # Position horizontale sur l'écran\n",
    "    WINDOW_POS_Y = 100   # Position verticale sur l'écran\n",
    "        \n",
    "    cap, video_writer = initialize_video_capture_and_writer()\n",
    "    \n",
    "    model = initialize_models()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "\n",
    "        # annotation des legos\n",
    "        annotationner_frame(model, frame, classe_choisie)\n",
    "\n",
    "        # Création et configuration de la fenêtre\n",
    "        cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(WINDOW_NAME, WINDOW_WIDTH, WINDOW_HEIGHT)\n",
    "        cv2.moveWindow(WINDOW_NAME, WINDOW_POS_X, WINDOW_POS_Y)\n",
    "        cv2.imshow(\"YOLOv8 Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_video(classe_choisie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
